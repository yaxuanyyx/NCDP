{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "af471b87-05c4-4cdc-8bac-87b46195dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "65f3bace-e3ad-428b-91ac-29f3cb2a4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('AWR370W_UserCourseTranscripts_2023-06-13-20-08-05.csv', low_memory=False)\n",
    "df2 = pd.read_csv('AWR390W_UserCourseTranscripts_2023-06-13-20-05-52.csv', low_memory=False)\n",
    "df3 = pd.read_csv('AWR391W_UserCourseTranscripts_2023-06-13-20-07-26.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "122ad856-04b8-4bfb-a08b-831c06231b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataset by module = course evaluation\n",
    "df1 = df1[df1['Module'] == 'Course Evaluation']\n",
    "df2 = df2[df2['Module'] == 'AWR-390 Course Evaluation ']\n",
    "df3 = df3[df3['Module'] == 'Evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e9962d0-511f-4a28-9d13-850b6f2d1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for Stu15\n",
    "df1 = df1[df1['Interaction Description'].isin(['Stu15 Which part(s) of the course was MOST valuable to you? Please explain why.'])]\n",
    "df2 = df2[df2['Interaction Description'].isin(['Stu15 Which part(s) of the course was MOST valuable to you? Please explain why.'])]\n",
    "df3 = df3[df3['Interaction Description'].isin(['Stu15 Which part(s) of the course was MOST valuable to you? Please explain why.'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff0a515c-9d67-4c0f-86a8-944b61943ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a specific column\n",
    "#column_data = df3['Interaction Description']\n",
    "#column_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b1714c-3cb3-41e2-868c-e49ef83c99db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWR370W Stu15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "08f9651b-6cd6-4002-a6c0-8ff675ed3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with blank values in 'Learner Response' column\n",
    "df1 = df1.dropna(subset=['Learner Response'], how='all')\n",
    "\n",
    "\n",
    "# Create a list of values to remove\n",
    "values_to_remove = ['n/a', 'na', 'NA', 'no', ' no answer', 'NOne']\n",
    "\n",
    "# Filter the DataFrame and keep rows where 'Learner Response' is not in the values to remove\n",
    "df1 = df1[~df1['Learner Response'].isin(values_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "87915b63-1960-4711-b5fc-92daf07529f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e9fbc2e3-02b0-4566-a88e-2291aa75309d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yyaxuan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b1a0988-8c4a-4c86-bb53-bea154fda041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract keywords from a specific column\n",
    "text_column_1 = df1['Learner Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0f038b4c-f742-419b-a06b-bbe3c4a3c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))  # Set of English stopwords\n",
    "all_keywords = []\n",
    "for text in text_column_1.astype(str):  # Convert values to strings\n",
    "    # Tokenize the text using the modified regular expression pattern\n",
    "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "    keywords = [token.lower() for token in tokens if token.lower() not in stop_words]  # Remove stopwords\n",
    "    all_keywords.extend(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e168d62d-4963-40b8-a734-00345f687aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of keywords\n",
    "keyword_counts = Counter(all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f8fe064a-af17-469c-a466-92ebfff40515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent keywords:\n",
      "damage 27\n",
      "course 18\n",
      "process 15\n",
      "disaster 15\n",
      "assessment 11\n",
      "knowledge 11\n",
      "learning 11\n",
      "fema 10\n",
      "information 9\n",
      "valuable 9\n",
      "different 8\n",
      "levels 8\n",
      "programs 8\n",
      "declaration 8\n",
      "housing 7\n",
      "Least frequent keywords:\n",
      "schema 1\n",
      "manage 1\n",
      "cooperate 1\n",
      "governments 1\n",
      "state 1\n",
      "knowlegde 1\n",
      "increasing 1\n",
      "always 1\n",
      "instruction 1\n",
      "preparedness 1\n"
     ]
    }
   ],
   "source": [
    "# Get the most frequent keywords (top 15)\n",
    "most_common_keywords = keyword_counts.most_common(15)\n",
    "print(\"Most frequent keywords:\")\n",
    "for keyword, count in most_common_keywords:\n",
    "    print(keyword, count)\n",
    "\n",
    "# Get the least frequent keywords (bottom 10), checking whether there are some typo\n",
    "least_common_keywords = keyword_counts.most_common()[:-11:-1]\n",
    "print(\"Least frequent keywords:\")\n",
    "for keyword, count in least_common_keywords:\n",
    "    print(keyword, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb88902-a943-4e4a-b8ef-561ffbd91a7c",
   "metadata": {},
   "source": [
    "Notes:\n",
    "important keywords:\n",
    "valuable, knowledge, instruction, assessment, course, learning, information, different/difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9c8dacf3-4397-4d03-8b48-17c06e402aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 401: The whole course was valuable knowledge.\n",
      "Row 2264: Most valuable was the home assessments because I do those for the Red Cross\n",
      "Row 2535: the entire course was very valuable to me\n",
      "Row 2642: All the course were very valuable to me just not good at testing\n",
      "Row 4448: The course overall was valuable as I have recently promoted to a position that oversees a housing program. The overview and information has given me knowledge to address housing needs if a disaster occurs. \n",
      "Row 4752: The links and guides are most valuable for further learning.\n",
      "Row 5679: The overall content was very valuable to me as a current first responder and emergency management student.\n",
      "Row 6067: Everything was valuable\n",
      "Row 6391: The content was invaluable because of my profession\n",
      "Row 7083: The most valuable part of this course was the pre and post exams. The reason why is because it allowed me to see what I did know versus what I had learned towards the end of the lesson. \n"
     ]
    }
   ],
   "source": [
    "# check all the reponses that include a certain keyword\n",
    "filtered_rows = df1.loc[df1['Learner Response'].str.contains('valuable', na=False)]\n",
    "\n",
    "# result\n",
    "for index, row in filtered_rows.iterrows():\n",
    "    row_number = index + 1\n",
    "    response_value = row['Learner Response']\n",
    "    print(f\"Row {row_number}: {response_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d7611a-3ff9-4085-97a8-8cc268dbf54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a04fa9-ee29-409b-94e6-04be9c027aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWR390W Stu15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8425f7a2-7160-4f19-88d1-08abd1892841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with blank values in 'Learner Response' column\n",
    "df2 = df2.dropna(subset=['Learner Response'], how='all')\n",
    "\n",
    "\n",
    "# Create a list of values to remove\n",
    "values_to_remove = ['.', 'a', 'N/a', 'na', 'NO COMMENT', 'none']\n",
    "\n",
    "# Filter the DataFrame and keep rows where 'Learner Response' is not in the values to remove\n",
    "df2 = df2[~df2['Learner Response'].isin(values_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c1ab1cfc-2e25-4e75-af98-be2c670e20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract keywords from a specific column\n",
    "text_column_2 = df2['Learner Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5ca5b4ce-915d-4d21-8427-340ed25df55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))  # Set of English stopwords\n",
    "all_keywords = []\n",
    "for text in text_column_2.astype(str):  # Convert values to strings\n",
    "    # Tokenize the text using the modified regular expression pattern\n",
    "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "    keywords = [token.lower() for token in tokens if token.lower() not in stop_words]  # Remove stopwords\n",
    "    all_keywords.extend(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c598d9d0-6750-4189-9117-16aa4d42f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of keywords\n",
    "keyword_counts = Counter(all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43080419-688d-42ef-b007-37564308d459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent keywords:\n",
      "disaster 18\n",
      "financial 15\n",
      "programs 12\n",
      "assistance 9\n",
      "information 9\n",
      "government 8\n",
      "available 8\n",
      "explanation 7\n",
      "preparedness 6\n",
      "understanding 6\n",
      "course 6\n",
      "learning 5\n",
      "personal 5\n",
      "valuable 5\n",
      "planning 5\n",
      "Least frequent keywords:\n",
      "governmental 1\n",
      "grants 1\n",
      "home 1\n",
      "strikes 1\n",
      "meet 1\n",
      "personally 1\n",
      "goals 1\n",
      "basic 1\n",
      "level 1\n",
      "grey 1\n"
     ]
    }
   ],
   "source": [
    "# Get the most frequent keywords (top 15)\n",
    "most_common_keywords = keyword_counts.most_common(15)\n",
    "print(\"Most frequent keywords:\")\n",
    "for keyword, count in most_common_keywords:\n",
    "    print(keyword, count)\n",
    "\n",
    "# Get the least frequent keywords (bottom 10), checking whether there are some typo\n",
    "least_common_keywords = keyword_counts.most_common()[:-11:-1]\n",
    "print(\"Least frequent keywords:\")\n",
    "for keyword, count in least_common_keywords:\n",
    "    print(keyword, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a6a4c2e4-4442-44dc-8306-5132a85cc75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 79: Explanation of government assistance\n",
      "Row 2408: explanations of the different government assist\n",
      "Row 4315: Learning which government agencies may respond in a hurricane, flood, fire etc.\n",
      "Row 5566: Section 4 contained interesting/useful information about the types of government assistance\n",
      "Row 5811: The part about government programs\n",
      "Row 5867: Explanation on government assistance\n",
      "Row 9825: The explanation of the different programs provided by the government.\n",
      "Row 10844: explanation of different governmental programs\n"
     ]
    }
   ],
   "source": [
    "# if you want to check all the reponses that include a certain keyword\n",
    "filtered_rows = df2.loc[df2['Learner Response'].str.contains('government', na=False)]\n",
    "\n",
    "# result\n",
    "for index, row in filtered_rows.iterrows():\n",
    "    row_number = index + 1\n",
    "    response_value = row['Learner Response']\n",
    "    print(f\"Row {row_number}: {response_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b5437-fe85-47d6-9468-1294ec0f5fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1e7cb-39be-4dab-993e-4c29f3db3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWR391W Stu15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dfae2c92-05ae-4888-b30c-202af0e80191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with blank values in 'Learner Response' column\n",
    "df3 = df3.dropna(subset=['Learner Response'], how='all')\n",
    "\n",
    "\n",
    "# Create a list of values to remove\n",
    "values_to_remove = ['n/a', 'na', 'None', 'a', 'x']\n",
    "\n",
    "# Filter the DataFrame and keep rows where 'Learner Response' is not in the values to remove\n",
    "df3 = df3[~df3['Learner Response'].isin(values_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7a83a584-a060-467d-9223-6bc06f590bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract keywords from a specific column\n",
    "text_column_3 = df3['Learner Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a70363b4-ef14-4851-a479-4140a6594ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))  # Set of English stopwords\n",
    "all_keywords = []\n",
    "for text in text_column_3.astype(str):  # Convert values to strings\n",
    "    # Tokenize the text using the modified regular expression pattern\n",
    "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "    keywords = [token.lower() for token in tokens if token.lower() not in stop_words]  # Remove stopwords\n",
    "    all_keywords.extend(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3524f32a-ce42-490a-9ec6-0bb7c36a26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of keywords\n",
    "keyword_counts = Counter(all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ce3cb204-453d-488c-95df-0b009c02d33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent keywords:\n",
      "disaster 4\n",
      "business 4\n",
      "valuable 3\n",
      "information 3\n",
      "course 3\n",
      "examples 2\n",
      "learning 2\n",
      "financial 2\n",
      "aspects 2\n",
      "given 1\n",
      "lessons 1\n",
      "concept 1\n",
      "preparing 1\n",
      "financially 1\n",
      "numerous 1\n",
      "Least frequent keywords:\n",
      "pertinent 1\n",
      "plans 1\n",
      "continuity 1\n",
      "important 1\n",
      "request 1\n",
      "relief 1\n",
      "chart 1\n",
      "flow 1\n",
      "documents 1\n",
      "safeguarding 1\n"
     ]
    }
   ],
   "source": [
    "# Get the most frequent keywords (top 15)\n",
    "most_common_keywords = keyword_counts.most_common(15)\n",
    "print(\"Most frequent keywords:\")\n",
    "for keyword, count in most_common_keywords:\n",
    "    print(keyword, count)\n",
    "\n",
    "# Get the least frequent keywords (bottom 10), checking whether there are some typo\n",
    "least_common_keywords = keyword_counts.most_common()[:-11:-1]\n",
    "print(\"Least frequent keywords:\")\n",
    "for keyword, count in least_common_keywords:\n",
    "    print(keyword, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3262ec04-c01e-4303-a722-2f58c865826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2502: small business investment \n",
      "Row 2534: Creating the business plan and how to do it effectively.\n",
      "Row 2766: business financial literacy and pre-disaster planning for financial aspects of disasters.\n"
     ]
    }
   ],
   "source": [
    "# if you want to check all the reponses that include a certain keyword\n",
    "filtered_rows = df3.loc[df3['Learner Response'].str.contains('business', na=False)]\n",
    "\n",
    "# result\n",
    "for index, row in filtered_rows.iterrows():\n",
    "    row_number = index + 1\n",
    "    response_value = row['Learner Response']\n",
    "    print(f\"Row {row_number}: {response_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22735062-18dd-4374-8936-611f2d13fefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7e960-6ec3-4e5a-8510-b9b2c140e94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f675a2-957c-4ee9-9528-2bba18f65d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586b8ec-81da-449e-a961-02050d697980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ec2ea-c396-473c-b8ba-b896590d9ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029d37c-b76e-4823-9382-eb266bc41bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
