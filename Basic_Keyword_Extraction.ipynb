{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29e7366e-57aa-48bc-95e2-965b783f2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9fc0fe5-a298-4321-bceb-703ba1d73974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('AWR370W_UserCourseTranscripts_2023-06-13-20-08-05.csv', low_memory=False)\n",
    "df2 = pd.read_csv('AWR390W_UserCourseTranscripts_2023-06-13-20-05-52.csv', low_memory=False)\n",
    "df3 = pd.read_csv('AWR391W_UserCourseTranscripts_2023-06-13-20-07-26.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85772e9d-b2d5-4f06-90c5-6328060bf0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataset by module = course evaluation\n",
    "df1 = df1[df1['Module'] == 'Course Evaluation']\n",
    "df2 = df2[df2['Module'] == 'AWR-390 Course Evaluation ']\n",
    "df3 = df3[df3['Module'] == 'Evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d7c6eda-7dcc-45a0-9c34-e0000ebf9254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter for Stu16\n",
    "df1 = df1[df1['Interaction Description'].isin(['Stu16 Which part(s) of the course was LEAST valuable to you? Please explain why.'])]\n",
    "df2 = df2[df2['Interaction Description'].isin(['Stu16 Which part(s) of the course was LEAST valuable to you? Please explain why.'])]\n",
    "df3 = df3[df3['Interaction Description'].isin(['Stu16 Which part(s) of the course was LEAST valuable to you? Please explain why.'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1ed690e-4fd1-4dda-8ed8-8150be97dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWR370W Stu16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f31d6d6-e349-44fa-a3cd-0dd48fa3f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with blank values in 'Learner Response' column\n",
    "df1 = df1.dropna(subset=['Learner Response'], how='all')\n",
    "\n",
    "\n",
    "# Create a list of values to remove\n",
    "values_to_remove = ['!', '.', 'no', 'no answer', ' none', 'none of it', 'None.', 'None. N/A',\n",
    "                   'nothing', 'THERE IS NONE', 'n.a', 'N/A', 'N/A all valuable','n/an/a', 'na']\n",
    "\n",
    "# Filter the DataFrame and keep rows where 'Learner Response' is not in the values to remove\n",
    "df1 = df1[~df1['Learner Response'].isin(values_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8085286-45ba-4d2d-99c3-7f178cc03b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50f60ab8-79a0-44d1-b636-bdfd8dc022f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yyaxuan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86422933-07d9-4148-b3ef-f85aefc7900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract keywords from a specific column\n",
    "text_column_1 = df1['Learner Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b209362-4c63-4cc6-b7e3-4912de69b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))  # Set of English stopwords\n",
    "all_keywords = []\n",
    "for text in text_column_1.astype(str):  # Convert values to strings\n",
    "    # Tokenize the text using the modified regular expression pattern\n",
    "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "    keywords = [token.lower() for token in tokens if token.lower() not in stop_words]  # Remove stopwords\n",
    "    all_keywords.extend(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3629999-146c-4a93-81fe-ccadaedc753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of keywords\n",
    "keyword_counts = Counter(all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0da37920-249f-4d15-9ad8-b96ba72f8483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent keywords:\n",
      "course 15\n",
      "valuable 10\n",
      "information 7\n",
      "damage 6\n",
      "think 6\n",
      "navigation 6\n",
      "test 5\n",
      "post 4\n",
      "good 4\n",
      "Least frequent keywords:\n",
      "explain 1\n",
      "identifying 1\n",
      "requests 1\n",
      "involved 1\n",
      "get 1\n",
      "unsure 1\n",
      "easy 1\n",
      "excelent 1\n",
      "us 1\n",
      "gives 1\n"
     ]
    }
   ],
   "source": [
    "# Get the most frequent keywords (top 10)\n",
    "most_common_keywords = [(keyword, count) for keyword, count in keyword_counts.most_common(10) if keyword.lower() != \"none\"]\n",
    "print(\"Most frequent keywords:\")\n",
    "for keyword, count in most_common_keywords:\n",
    "    print(keyword, count)\n",
    "\n",
    "# Get the least frequent keywords (bottom 10), checking whether there are some typo\n",
    "least_common_keywords = [(keyword, count) for keyword, count in keyword_counts.most_common()[:-11:-1] if keyword.lower() != \"none\"]\n",
    "print(\"Least frequent keywords:\")\n",
    "for keyword, count in least_common_keywords:\n",
    "    print(keyword, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0cd21d0d-8630-422b-983b-407137cba645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 416: None. All part of the course were valuable.\n",
      "Row 2528: the entire course was very valuable to me\n",
      "Row 2629: None was least valuable all information was very important\n",
      "Row 3025: All was valuable\n",
      "Row 3958: all part(s) were valuable.\n",
      "Row 4188: None.  All of it was valuable.\n",
      "Row 4781: More case studies or examples throughout would have been more valuable. \n",
      "Row 6044: none , the entire course was valuable and all of its content. \n",
      "Row 6122: Everything was valuable to me.\n",
      "Row 7074: I do not think that there was a least valuable part of this course because of the fact that I did not know much on this topic. \n"
     ]
    }
   ],
   "source": [
    "# check all the reponses that include a certain keyword\n",
    "filtered_rows = df1.loc[df1['Learner Response'].str.contains('valuable', na=False)]\n",
    "\n",
    "# result\n",
    "for index, row in filtered_rows.iterrows():\n",
    "    row_number = index + 1\n",
    "    response_value = row['Learner Response']\n",
    "    print(f\"Row {row_number}: {response_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b56255ef-a92c-4114-aade-11103c65cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWR390W Stu16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87a41b53-6fb5-491c-898b-7b71ae161d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with blank values in 'Learner Response' column\n",
    "df2 = df2.dropna(subset=['Learner Response'], how='all')\n",
    "\n",
    "\n",
    "# Create a list of values to remove\n",
    "values_to_remove = ['?', '.', 'N/a', 'None', 'Not applicable', 'NOTHING', 'na', 'NO COMMENT']\n",
    "\n",
    "# Filter the DataFrame and keep rows where 'Learner Response' is not in the values to remove\n",
    "df2 = df2[~df2['Learner Response'].isin(values_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da00704d-1ab8-4645-b620-ea4a89d7e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract keywords from a specific column\n",
    "text_column_2 = df2['Learner Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ef0e17a-f8e2-4e66-bcea-d673e80385bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))  # Set of English stopwords\n",
    "all_keywords = []\n",
    "for text in text_column_2.astype(str):  # Convert values to strings\n",
    "    # Tokenize the text using the modified regular expression pattern\n",
    "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "    keywords = [token.lower() for token in tokens if token.lower() not in stop_words]  # Remove stopwords\n",
    "    all_keywords.extend(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0cd0326-91c1-4862-8cca-a4d2b49cd07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of keywords\n",
    "keyword_counts = Counter(all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7723a8d5-0f1c-467b-b198-4dc7392bf950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent keywords:\n",
      "course 12\n",
      "valuable 9\n",
      "financial 9\n",
      "insurance 8\n",
      "basic 7\n",
      "disaster 6\n",
      "debt 6\n",
      "already 5\n",
      "hurricane 4\n",
      "Least frequent keywords:\n",
      "budgeting 1\n",
      "invaluable 1\n",
      "whole 1\n",
      "complete 1\n",
      "failing 1\n",
      "first 1\n",
      "answers 1\n",
      "useless 1\n",
      "exercises 1\n",
      "graph 1\n"
     ]
    }
   ],
   "source": [
    "# Get the most frequent keywords (top 10)\n",
    "most_common_keywords = [(keyword, count) for keyword, count in keyword_counts.most_common(10) if keyword.lower() != \"none\"]\n",
    "print(\"Most frequent keywords:\")\n",
    "for keyword, count in most_common_keywords:\n",
    "    print(keyword, count)\n",
    "\n",
    "# Get the least frequent keywords (bottom 10), checking whether there are some typo\n",
    "least_common_keywords = [(keyword, count) for keyword, count in keyword_counts.most_common()[:-11:-1] if keyword.lower() != \"none\"]\n",
    "print(\"Least frequent keywords:\")\n",
    "for keyword, count in least_common_keywords:\n",
    "    print(keyword, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "66573e3b-a3ff-4a1b-8f64-996252f7da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 609: Steps to take after disaster  the 5 steps is important because you can pass one without the other\n",
      "Row 5127: Types of FEMA disasters.  I was already aware of these disaster types.\n",
      "Row 6957: THw definitions of disasters, just because I already knew it, but it is important\n",
      "Row 7935: What to do after a disaster, I have lived it having been wiped out by hurricane Andrew\n"
     ]
    }
   ],
   "source": [
    "# if you want to check all the reponses that include a certain keyword\n",
    "filtered_rows = df2.loc[df2['Learner Response'].str.contains('disaster', na=False)]\n",
    "\n",
    "# result\n",
    "for index, row in filtered_rows.iterrows():\n",
    "    row_number = index + 1\n",
    "    response_value = row['Learner Response']\n",
    "    print(f\"Row {row_number}: {response_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e23616b5-f947-4a93-a2d3-09431a2e4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWR391W Stu16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cfa89d3e-5f43-4036-87f9-6667bc4f8829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with blank values in 'Learner Response' column\n",
    "df3 = df3.dropna(subset=['Learner Response'], how='all')\n",
    "\n",
    "\n",
    "# Create a list of values to remove\n",
    "values_to_remove = ['-', 'n/a', 'na', 'None', 'None.', 'Nothing!']\n",
    "\n",
    "# Filter the DataFrame and keep rows where 'Learner Response' is not in the values to remove\n",
    "df3 = df3[~df3['Learner Response'].isin(values_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c41f1336-6809-46ea-96ad-5dfb010a3797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract keywords from a specific column\n",
    "text_column_3 = df3['Learner Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "beddea58-6961-4931-b8d3-ba8f45b26a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))  # Set of English stopwords\n",
    "all_keywords = []\n",
    "for text in text_column_3.astype(str):  # Convert values to strings\n",
    "    # Tokenize the text using the modified regular expression pattern\n",
    "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "    keywords = [token.lower() for token in tokens if token.lower() not in stop_words]  # Remove stopwords\n",
    "    all_keywords.extend(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e28baa9a-e519-4a45-a998-3e00019f72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of keywords\n",
    "keyword_counts = Counter(all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "180b0acd-30b0-45f4-8372-037beec217ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent keywords:\n",
      "course 4\n",
      "information 2\n",
      "test 2\n",
      "think 2\n",
      "least 2\n",
      "valuable 2\n",
      "section 1\n",
      "dealing 1\n",
      "opportunity 1\n",
      "Least frequent keywords:\n",
      "parts 1\n",
      "whole 1\n",
      "disaster 1\n",
      "planning 1\n",
      "finacial 1\n",
      "awareness 1\n",
      "us 1\n",
      "give 1\n",
      "knowedgeable 1\n",
      "lessons 1\n"
     ]
    }
   ],
   "source": [
    "# Get the most frequent keywords (top 10)\n",
    "most_common_keywords = [(keyword, count) for keyword, count in keyword_counts.most_common(10) if keyword.lower() != \"none\"]\n",
    "print(\"Most frequent keywords:\")\n",
    "for keyword, count in most_common_keywords:\n",
    "    print(keyword, count)\n",
    "\n",
    "# Get the least frequent keywords (bottom 10), checking whether there are some typo\n",
    "least_common_keywords = [(keyword, count) for keyword, count in keyword_counts.most_common()[:-11:-1] if keyword.lower() != \"none\"]\n",
    "print(\"Least frequent keywords:\")\n",
    "for keyword, count in least_common_keywords:\n",
    "    print(keyword, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d96181f-85cd-4d68-9fbb-6225b3fc4f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 432: The section dealing with opportunity cost. Very little information on the concept and test question was difficult to understand. \n",
      "Row 2724: Overall, I do not think that there was a part of this course that was least valuable to me due to the fact that I feel as though everything within the course helped me learn a lot of information \n"
     ]
    }
   ],
   "source": [
    "# if you want to check all the reponses that include a certain keyword\n",
    "filtered_rows = df3.loc[df3['Learner Response'].str.contains('information', na=False)]\n",
    "\n",
    "# result\n",
    "for index, row in filtered_rows.iterrows():\n",
    "    row_number = index + 1\n",
    "    response_value = row['Learner Response']\n",
    "    print(f\"Row {row_number}: {response_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428861c-920b-4063-9faa-c82e5a5a157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### focus on comments \"positive'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
